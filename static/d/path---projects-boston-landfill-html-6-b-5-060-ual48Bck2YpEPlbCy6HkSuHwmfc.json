{"data":{"markdownRemark":{"html":"<p>This is a project I became interested in a long time ago.  I have been in Boston for over 12 years, and knew that Boston was built over time from a series of landfill projects.  I was interested in creating an app that allowed a user to scrub through time and see what parts of Boston were changed and when.  </p>\n<p>After a little bit of digging, I found this dataset <a href=\"http://www.bc.edu/bc_org/avp/cas/fnart/fa267/sequence.html\">here</a>, an extremely poor quality GIF.  I probably could have emailed the professor for something of higher quality, but since I am always up for a challenge, I wanted to use this to practice a variety of skills:</p>\n<ul>\n<li>Understand GIFs in Python</li>\n<li>Some basic image processing: dilation/erosion, thresholding, smoothing, etc.</li>\n<li>Extract contours/shapes from an image</li>\n<li>Shape manipulations: merging, intersection</li>\n<li>SVG creation</li>\n<li>GeoJSON creation</li>\n<li>Interactive React App with GeoJSON objects</li>\n<li>React App for timelines, and other Interactive elements</li>\n</ul>\n<h2 id=\"data\"><a href=\"#data\" aria-hidden=\"true\" class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Data</h2>\n<p>Original data was sourced here, a GIF image: <a href=\"http://www.bc.edu/bc_org/avp/cas/fnart/fa267/sequence.html\">http://www.bc.edu/bc_org/avp/cas/fnart/fa267/sequence.html</a></p>\n<h2 id=\"key-lessons-learned\"><a href=\"#key-lessons-learned\" aria-hidden=\"true\" class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Key Lessons Learned</h2>\n<h3 id=\"read-gif-in-python\"><a href=\"#read-gif-in-python\" aria-hidden=\"true\" class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Read GIF in Python</h3>\n<p>A colored GIF is just a <code class=\"language-text\">F x M x N x C</code> tensor, where <code class=\"language-text\">F</code> is the number of frames, <code class=\"language-text\">M</code> and <code class=\"language-text\">N</code> are the height and width, and <code class=\"language-text\">C=3</code> are the 3 RGB channels.</p>\n<p>Easy to read image (and make Greyscale):</p>\n<div class=\"gatsby-highlight\" data-language=\"python\">\n      <pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> skimage<span class=\"token punctuation\">.</span>io <span class=\"token keyword\">import</span> imread\n<span class=\"token keyword\">from</span> skimage<span class=\"token punctuation\">.</span>color <span class=\"token keyword\">import</span> rgb2gray\n\nimage <span class=\"token operator\">=</span> rgb2gray<span class=\"token punctuation\">(</span>imread<span class=\"token punctuation\">(</span><span class=\"token string\">'img.gif'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n      </div>\n<h3 id=\"basic-image-processing\"><a href=\"#basic-image-processing\" aria-hidden=\"true\" class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Basic Image Processing</h3>\n<h4 id=\"resizing\"><a href=\"#resizing\" aria-hidden=\"true\" class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Resizing</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\">\n      <pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> skimage<span class=\"token punctuation\">.</span>transform <span class=\"token keyword\">import</span> resize <span class=\"token keyword\">as</span> resize_image\n\nimage <span class=\"token operator\">=</span> resize_image<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token number\">1000</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1000</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n      </div>\n<h4 id=\"slight-blur\"><a href=\"#slight-blur\" aria-hidden=\"true\" class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Slight blur</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\">\n      <pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> skimage<span class=\"token punctuation\">.</span>filters <span class=\"token keyword\">import</span> gaussian\n\nimage <span class=\"token operator\">=</span> gaussian<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span></code></pre>\n      </div>\n<h4 id=\"thresholding\"><a href=\"#thresholding\" aria-hidden=\"true\" class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Thresholding</h4>\n<p>I used <code class=\"language-text\">threshold_minimum</code> which is described as: The histogram of the input image is computed and smoothed until there are only two maxima. Then the minimum in between is the threshold value.</p>\n<p>It is described in more detail <a href=\"http://scikit-image.org/docs/dev/auto_examples/xx_applications/plot_thresholding.html#bimodal-histogram\">here</a></p>\n<div class=\"gatsby-highlight\" data-language=\"python\">\n      <pre class=\"language-python\"><code class=\"language-python\">threshold <span class=\"token operator\">=</span> threshold_minimum<span class=\"token punctuation\">(</span>rimage<span class=\"token punctuation\">)</span>\n\nbinary <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>image <span class=\"token operator\">></span> threshold<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span><span class=\"token builtin\">int</span><span class=\"token punctuation\">)</span>\n  <span class=\"token comment\"># binary = binary_dilation(binary)</span>\n\n  <span class=\"token keyword\">return</span> binary</code></pre>\n      </div>\n<h4 id=\"erosiondilation\"><a href=\"#erosiondilation\" aria-hidden=\"true\" class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Erosion/Dilation</h4>\n<div class=\"gatsby-highlight\" data-language=\"python\">\n      <pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> skimage<span class=\"token punctuation\">.</span>morphology <span class=\"token keyword\">import</span> binary_dilation<span class=\"token punctuation\">,</span> binary_erosion\n\nimage <span class=\"token operator\">=</span> binary_dilation<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">)</span></code></pre>\n      </div>\n<h3 id=\"get-contours-from-image\"><a href=\"#get-contours-from-image\" aria-hidden=\"true\" class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Get contours from image</h3>\n<p>This creates contours where image = 0. Since we created a binary image with thresholding, this is easy.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\">\n      <pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> skimage <span class=\"token keyword\">import</span> measure\n\ncontours <span class=\"token operator\">=</span> measure<span class=\"token punctuation\">.</span>find_contours<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span></code></pre>\n      </div>\n<h3 id=\"contour-to-shapes\"><a href=\"#contour-to-shapes\" aria-hidden=\"true\" class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Contour to Shapes</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\">\n      <pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> shapely<span class=\"token punctuation\">.</span>geometry <span class=\"token keyword\">import</span> Polygon\n\npolygon <span class=\"token operator\">=</span> Polygon<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">)</span></code></pre>\n      </div>\n<h3 id=\"simplify-shapes\"><a href=\"#simplify-shapes\" aria-hidden=\"true\" class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Simplify shapes</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\">\n      <pre class=\"language-python\"><code class=\"language-python\">p <span class=\"token operator\">=</span> polygon<span class=\"token punctuation\">.</span>simplify<span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> preserve_topology<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span></code></pre>\n      </div>\n<h3 id=\"convert-contours-to-svg\"><a href=\"#convert-contours-to-svg\" aria-hidden=\"true\" class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Convert contours to SVG</h3>\n<p>In order to convert Shapely shapes to SVG, I manually built my own SVG path elements, similar to this:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\">\n      <pre class=\"language-python\"><code class=\"language-python\">path <span class=\"token operator\">=</span> svgwrite<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>Path<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\next_points <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>shape<span class=\"token punctuation\">.</span>exterior<span class=\"token punctuation\">.</span>coords<span class=\"token punctuation\">)</span>\n\nP <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">'M'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>ext_points<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>ext_points<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">'L'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> x <span class=\"token keyword\">in</span> ext_points<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Z'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">[</span>path<span class=\"token punctuation\">.</span>push<span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>x<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> x <span class=\"token keyword\">in</span> P<span class=\"token punctuation\">]</span>\n\n<span class=\"token keyword\">for</span> interior <span class=\"token keyword\">in</span> shape<span class=\"token punctuation\">.</span>interiors<span class=\"token punctuation\">:</span>\n    int_points <span class=\"token operator\">=</span> <span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>interior<span class=\"token punctuation\">.</span>coords<span class=\"token punctuation\">)</span>\n\n    P <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">'M'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>int_points<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>int_points<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">'L'</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> x <span class=\"token keyword\">in</span> int_points<span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token string\">'Z'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">[</span>path<span class=\"token punctuation\">.</span>push<span class=\"token punctuation\">(</span><span class=\"token operator\">*</span>x<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> x <span class=\"token keyword\">in</span> P<span class=\"token punctuation\">]</span></code></pre>\n      </div>\n<h3 id=\"convert-svg-to-polygons\"><a href=\"#convert-svg-to-polygons\" aria-hidden=\"true\" class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Convert SVG to Polygons</h3>\n<p>In order to convert Shapely shapes to SVG, I manually built my own SVG path elements, similar to this:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\">\n      <pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> shapely<span class=\"token punctuation\">.</span>geometry <span class=\"token keyword\">import</span> Polygon<span class=\"token punctuation\">,</span> MultiPolygon\n<span class=\"token keyword\">from</span> xml<span class=\"token punctuation\">.</span>dom <span class=\"token keyword\">import</span> minidom<span class=\"token punctuation\">,</span> Node\n<span class=\"token keyword\">from</span> svg<span class=\"token punctuation\">.</span>path <span class=\"token keyword\">import</span> parse_path <span class=\"token keyword\">as</span> parse_svg_path\n\nsvg_doc <span class=\"token operator\">=</span> minidom<span class=\"token punctuation\">.</span>parse<span class=\"token punctuation\">(</span><span class=\"token string\">\"data/svg_out.svg\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">parse_path</span><span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    points <span class=\"token operator\">=</span> <span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> <span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">.</span>real<span class=\"token punctuation\">,</span> x<span class=\"token punctuation\">.</span>start<span class=\"token punctuation\">.</span>imag<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> parse_svg_path<span class=\"token punctuation\">(</span>path<span class=\"token punctuation\">.</span>getAttribute<span class=\"token punctuation\">(</span><span class=\"token string\">'d'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> points\n\npoints <span class=\"token operator\">=</span> parse_path<span class=\"token punctuation\">(</span>svg_doc<span class=\"token punctuation\">.</span>getElementsByTagName<span class=\"token punctuation\">(</span><span class=\"token string\">\"path\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\nPolygon<span class=\"token punctuation\">(</span>points<span class=\"token punctuation\">)</span></code></pre>\n      </div>\n<h3 id=\"convert-polygons-to-geojson\"><a href=\"#convert-polygons-to-geojson\" aria-hidden=\"true\" class=\"anchor\"><svg aria-hidden=\"true\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Convert Polygons to GeoJSON</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\">\n      <pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> shapely<span class=\"token punctuation\">.</span>geometry <span class=\"token keyword\">import</span> mapping\n<span class=\"token keyword\">import</span> json\n\nout <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token string\">\"type\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"FeatureCollection\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"features\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>\n        <span class=\"token punctuation\">{</span>\n            <span class=\"token string\">\"type\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Feature\"</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"properties\"</span><span class=\"token punctuation\">:</span> <span class=\"token punctuation\">{</span> <span class=\"token string\">\"layer\"</span><span class=\"token punctuation\">:</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"region\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"logan_airport\"</span> <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n            <span class=\"token string\">\"geometry\"</span><span class=\"token punctuation\">:</span> mapping<span class=\"token punctuation\">(</span>shape<span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">]</span>        \n<span class=\"token punctuation\">}</span>\n\njson<span class=\"token punctuation\">.</span>dump<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">,</span> <span class=\"token builtin\">open</span><span class=\"token punctuation\">(</span><span class=\"token string\">'test.geojson'</span><span class=\"token punctuation\">,</span> <span class=\"token string\">'w'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre>\n      </div>","frontmatter":{"title":"Boston Landfill","startDate":"2017-10-06","endDate":"2017-10-23","repoURL":"https://github.com/dvreed77/boston_landfill","projectURL":"https://dvreed77.github.io/boston_landfill/","images":[{"publicURL":"/static/boston-landfill-60905d0ced07df3d6eecfa2ea1ea9220.png","childImageSharp":{"fluid":{"tracedSVG":"data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' width='400' height='400' viewBox='0 0 400 400' version='1'%3e%3crect width='100%25' height='100%25' fill='%23EDEEF0'/%3e%3cpath d='M250 35a2458 2458 0 0 0-2 61c-1-3-1-3-1 1 0 2 1 3 2 3l1 15v14H125a7347 7347 0 0 0 0 1h125v10l1 9 1-9v-10h74a2691 2691 0 0 0 0-1h-74v-26c0-16 0-25 1-24v-5l1-2h-1l-1-36-1-36-1 35m-44 12v6c0 3 1 4 3 4l4-1c1-2 2-2 3 0h8c3 2 5 0 4-4 0-2-1-3-3-3-3 0-3 3 0 5 2 0 2 1 1 1-2 0-4-1-4-3-1-4-6-4-7-1-1 2-1 2-1-1s-1-4-5-4l-3 1m-7 1c-1 1-2 2-3 1-4 0-5 2-2 4l3 2h-3c-2 0-3-1-3-3-1-4-5-3-5 1v4h6c5 0 6-1 6-2 0-5 0-5 1-2 1 7 3 3 2-5 0-2-2-1-2 0m-5 48v9h26V86h-26v10m-72 41c-2 3-1 8 2 9l3-1c0-2 0-2 2 0h4c2-1 2-7 0-8-2-2-5 0-5 3 0 2 0 2-2 1l-2-1-1-1 2-1h2c-1-2-4-2-5-1m235 1l1 3v2c-2 1 0 3 2 3l3-2v-2l2 2c3 4 8 1 5-3v-2c2-1 0-3-2-3l-3 2h-2c-1-2-5-3-6 0M0 269v100h2c2 0 3 2 4 4 1 4 3 6 4 4 2-1 3 0 7 3 4 4 5 4 8 4 8-1 11-2 13-4h9c6-2 7-2 8-5 1-5 1-6 3-6l4 1c0 1 11 1 18-1h10c6 1 9 0 10-4l1-7v-7c-3-3-2-4 0-8 3-4 4-5 6-2 3 4 7 0 5-5-3-5-1-13 3-13l4-2 3-1-2-2h-4c-2 2-4 0-4-4v-4l-1 4v5H91l-1-5c0-5-2-5-2 0s-1 6-5 4c-2-1-2-2-1-4 2-3 0-4-2-1-3 5-10 0-7-6 2-3 4-4 6-2 3 4 5 2 2-1v-2h2c1-1-5-3-6-2-1 0-1 1 1 1l3 1h-3l-5 1-1-1c1-1 0-1-1-1l-3-1c0-3-2-2-5 0l-3 2c-2-1-3 7-1 10 1 3 0 4-2 3-5-1-4-17 2-23 3-3 3-3 1-7-1-5-3-6-12-6-8 0-8 0-12-4-4-3-4-4-3-5 2-3 5-2 10 1 4 4 5 4 7 1 2-2 2-2 6-1l7 4 6 3c6 1 15 7 15 11 0 2 7 5 11 4l9-2c19-3 23-7 25-23 0-10 0-10-2-13l-3-1c-1 1-1 1-3-1-2-3-5-4-9-4-5 0-9-2-10-4 0-3 1-5 3-3l11 1c2 0 4-1 6-4l4-5c3 0 8-3 9-6 4-6 15 0 15 9 0 2 1 4 4 7 5 4 5 7 2 10l-2 2 3 3 7 4c7 3 8 3 8 8s1 6 4 3c4-4 10-1 8 3-3 5-14 10-16 7-1-2-5-1-5 1-3 10-2 12 9 10 7-1 12 0 14 4 6 13 8 16 10 12l3-1c2 0 2 0 0 1-2 0-2 1-2 8 0 8 2 10 2 2l1-4 1 4c2 5 3 6 5 4l1-1-1 3-1 4c0 4 2 5 11 5 3 0 4 0 1 1h-4v6c0 6 2 7 2 1 1-7 4-7 4-1 0 7 3 7 3 0 0-5 1-6 4-7l3-3 3-1c2 0 3 2 2 11 0 6 0 6-4 6h-7c-2 3-5 0-5-5 0-2 0-4-1-3l-1 4c0 4 0 4-3 4h-5c-4 1-8-1-8-4 0-4-7-2-8 1 0 2-1 3-3 3s-2 0-2-8l1-8 3-1h4l-6-6-8-6c-4 0-10 2-13 5-3 2-5 3-8 3h-3l4 4c4 3 4 3 2 5l-3 2c-1-1-2 0-3 1-2 2-4 1-2-1v-4c-3-2-8-3-9-1l-3 1c-2 0-3 1-6 7-2 5-3 6-5 6s-7 6-12 14l-3 4c-3 3-3 6 0 6h7l2 4c0 2 0 2-1 1-3-3-9-3-13 1-2 2-4 3-9 3-6 1-13 4-14 6l-4 2-5 3-4 1c-2-1-3 0-6 2l-5 4c-1 1 5 1 28 1l30-1h1l3 1 2-1 1-1c2 0 2 0 1 1s-1 1 2 1c2 0 3-1 2-7 0-5 1-6 2-4l1 3c-2 4-1 8 1 8s2 0 1-2 0-6 2-6v1c-2 2-1 5 1 5 1-1 1-1 1 1-1 1 0 1 1 1 2-1 3-6 1-8-1-1-1-2 1-2h2l-1 2c3 9 6 11 8 4a694 694 0 0 1 0-6l-1-1h3c3 1 3 1 1 4s-1 7 2 7c2 0 2 0 1-1-1-2-1-2 2-2 4 0 6-3 3-6v-1c2 0 3 5 3 8l-1 2h37c35 0 36 0 38-2 3-3 8-4 12-1l3 3h142v-4l-2-21-1 6 1 5 1 4c0 3 0 4-1 3l-1-3c0-2 0-2-4-2s-4 0-4-3v-2l-2 2-3 2c-4 0-4-1-1-8 2-6 3-12 2-14l-1-8c0-7 0-7-3-9-3-1-3-1-1-4 1-3 3-4 2-1h1c1-2 1-1 1 3 0 2 0 2 2 2 3 0 3 0 3 7l1 6 1-6 2-6 2-4c1-3 3-2 4 3 0 3 0 5-2 7-3 3-3 5 0 8l1 2c-1 0-2 1-2 3 0 3 3 3 4 0V170H268l-133 1 3 6 8 13 3-6 3-7c2 0 1 2-2 8-2 6-2 6 0 7 3 2 8 8 8 10 0 3 4 5 12 5 12 0 20 1 21 3l-2 5c-2 5-3 12-1 13l5-10 5-9h4l5 2h-2c-2 0-7 8-5 10s5-1 7-5l3-3-1 4c-2 4-2 4 0 6 2 1 3 0 6-6l2-5h8l7 1 9 1c9 1 20 3 24 6h3c1 0 2 0 2 2l1 3 2 4c0 2 0 3-5 3-7 0-5 3 2 3 5 0 5 0 5 7 0 5-1 5-11 3-28-8-46-11-47-8 0 2 6 5 14 6l9 2a490 490 0 0 0 31 6c1 1 3 13 2 14 0 2-1 1-5-2-3-4-5-5-8-5s-5-1-7-3c-4-3-7-4-13-3-5 0-6 3-3 11 1 4-3 3-6-2-2-3-4-4-7-5-5-1-27-12-32-15l-11-8-10-5c-3-2-5-2-12-3-12 0-16-2-19-7-3-6-14-40-14-44v-4H0v99m399-60l-10 7-9 8c-1 5-6 4-8 0-1-3-3-4-4-4-3 0-9 7-10 13-1 3-1 3 3 4 2 0 4 2 5 3l8 2 9 2c4 0 8-1 7-3l2-4 2-6 3-4c3-3 3-3 3-11l-1-7m-32 52c-2 2-1 19 0 18a39 39 0 0 1 16-1c6 1 9 8 2 8h-4l3 1c3 0 6 2 4 3h-5l3 2c5 1 4 5-1 6-4 0-6-2-4-4l1 1h4l-3-2-3-3c0-3-5-6-8-4-2 0-3 0-4-2s-1-2-7-2l-6 1 1 16h5c7-1 8-1 8-6 0-6 7-9 9-3 2 5 0 8-5 8-4-1-4-1-3 1h7c2-1 2-1 4 1 1 2 2 2 3 1s5-3 7-2h5c4 1 6 0 2-1s-3-11 0-11l2-1h-2c-2 0-3 0-8-6-3-2-1-3 3-2l7-2h-4l-5-1c0-3 1-4 2-2h4l-3-2-3-3-1-3h-9l-6 1h-4l4-1c3 0 5-1 5-2 0-2 0-2-1-1l-5 1c-3 0-4 0-4 2s1 2 4 2l4 1-4 1c-4 0-4 0-4 3 0 2 0 2 5 2l4 1-6 1h-5v-14l6-1 6-1h-7l-6 1m-107 10l-3 3c-1 3-2 3-5 3-3-1-4-1-7 3-2 3-4 4-5 4-4-1-3-4 0-8 3-3 3-5 0-4l-6 1c-6 1-7 2-4 7 3 4 3 11-1 14l-3 2 4 4c6 5 12 4 7-1-2-3 0-4 4-2l4 2c0-1-2-6-6-10l-1-3 10 10 9 9-3-4-2-5c1-1 2 0 4 2l5 4c2 0 1-1-2-4s-4-6-2-6l3 3 4 3-3-5c-1-2-3-4-2-5 1-2 2-1 4 3 3 3 6 3 4 0l-2-4a1081 1081 0 0 0-7-10c2-3 2-3 7 2 5 4 8 5 8 2 0-1-11-11-13-10m96 20v7h4c6 0 9-2 7-5v-5c0-4-2-5-7-5h-4v8m-149 4c-3 3-3 4 0 8 3 3 3 6 0 8s-5 3-5 1l-1-1 3 10 2-5c3-8 5-7 5 2l-1 8-1-5c0-5 0-5-1-3s0 8 1 9h17v-8c0-8 0-9 3-10l2-2c0-1-8-6-10-5-3 0-5-1-7-5s-4-5-7-2m-97 5l-8 1c-9-1-14 0-14 2l2 2c3 0 6 2 6 4h6l-3 2c-7 1-5 7 2 7l4-1v-4l-1-6c-1-1 2-2 6-2l2-2 2-2 2-1h-6m7 4c0 2 0 3 2 2v1c-2 3-1 9 1 10 3 1 7 0 7-2h-6c-1-2-1-2 2-2s4 0 4-2c0-3-2-5-5-5-2 0-2 0-1-1v-2c-2-3-4-2-4 1m246 13v2h-3l-2 1c1 1 0 1-1 1v2l3 1c2-1 2-1 0 3s-2 4 0 6h4l2-1c5 0 7-11 2-14l-3-2-2 1m-174 24l1 7 1-3c0-3 0-3 3-3 4 0 6-1 6-4 0-4-2-5-7-5h-4v8m42-6c0 2-1 2-3 2-4 0-6 4-4 8 0 2 1 3 5 3h4v-8l-1-7-1 2m76 2c-2 3-1 5 2 5 2 0 2 2 0 6-4 5-3 7 0 8 2 0 3-1 5-5l2-5v-3c2-2 1-6-1-4l-1-2c0-2-2-3-4-3l-3 3m-61 46l1 9h10a140 140 0 0 0 19-2c-3 0-4-1-4-2-1-2 0-3 1-1h4l-3-2c-3-1-3-1-3-3 1-3-1-4-7-4-3 0-4 0-4-2s-1-2-7-2h-7v9M1 393c0 7 0 8 4 6h4l22 1c0-2-3-6-5-7l-5-3-19-5-1 8' fill='%23FCCB0A' fill-rule='evenodd'/%3e%3c/svg%3e","aspectRatio":2,"src":"/static/boston-landfill-60905d0ced07df3d6eecfa2ea1ea9220-ffa97.png","srcSet":"/static/boston-landfill-60905d0ced07df3d6eecfa2ea1ea9220-604a8.png 250w,\n/static/boston-landfill-60905d0ced07df3d6eecfa2ea1ea9220-8d7ef.png 500w,\n/static/boston-landfill-60905d0ced07df3d6eecfa2ea1ea9220-ffa97.png 600w","sizes":"(max-width: 600px) 100vw, 600px"}}}]},"fields":{"path":"projects/boston-landfill.md","slug":"/projects/boston-landfill.html"}}},"pageContext":{"jsonName":"projects-boston-landfill-html-6b5","internalComponentName":"ComponentProjectsBostonLandfillHtml","path":"/projects/boston-landfill.html","component":"/Users/dreed/personal_code/dvreed.com/src/templates/project.js","componentChunkName":"component---src-templates-project-js","context":{"slug":"/projects/boston-landfill.html"},"updatedAt":1529279935540,"pluginCreator___NODE":"Plugin default-site-plugin","pluginCreatorId":"Plugin default-site-plugin","componentPath":"/Users/dreed/personal_code/dvreed.com/src/templates/project.js","slug":"/projects/boston-landfill.html"}}